{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc130d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP ‚Äî Run this first!\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Verify versions\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version:      {np.__version__}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úÖ GPU available: {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU detected. Go to Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd26e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"mahmoudreda55/satellite-image-classification\")\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "# Print structure to understand folder layout\n",
    "print(\"\\nDataset structure:\")\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    level = root.replace(dataset_path, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/  ({len(files)} files)\")\n",
    "    if level >= 3:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def file_hash(path, chunk_size=8192):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "seen = {}\n",
    "duplicates = []\n",
    "\n",
    "for root_dir, _, file_list in os.walk(dataset_path):\n",
    "    for fname in file_list:\n",
    "        if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "        fpath = os.path.join(root_dir, fname)\n",
    "        h = file_hash(fpath)\n",
    "        if h in seen:\n",
    "            duplicates.append(fpath)\n",
    "        else:\n",
    "            seen[h] = fpath\n",
    "\n",
    "for dup in duplicates:\n",
    "    os.remove(dup)\n",
    "\n",
    "print(f\"Total images scanned: {len(seen) + len(duplicates)}\")\n",
    "print(f\"Duplicates removed: {len(duplicates)}\")\n",
    "print(f\"Unique images remaining: {len(seen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161058d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(dataset_path, \"data\")\n",
    "\n",
    "batch_size = 64\n",
    "img_size = (64, 64)\n",
    "seed = 42\n",
    "\n",
    "full_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "class_names = full_ds.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Inspect a single batch\n",
    "for images, labels in full_ds.take(1):\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "\n",
    "# Class distribution in full_ds\n",
    "num_classes = len(class_names)\n",
    "class_counts = np.zeros(num_classes, dtype=int)\n",
    "\n",
    "for _, labels in full_ds:\n",
    "    class_counts += np.bincount(labels.numpy(), minlength=num_classes)\n",
    "\n",
    "for name, count in zip(class_names, class_counts):\n",
    "    print(f\"{name}: {count}\")\n",
    "\n",
    "full_ds = full_ds.shuffle(1000, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "total_batches = tf.data.experimental.cardinality(full_ds).numpy()\n",
    "test_batches = max(1, total_batches // 10)\n",
    "val_batches = max(1, total_batches // 10)\n",
    "\n",
    "test_ds = full_ds.take(test_batches)\n",
    "val_ds = full_ds.skip(test_batches).take(val_batches)\n",
    "train_ds = full_ds.skip(test_batches + val_batches)\n",
    "\n",
    "print(f\"Train batches: {tf.data.experimental.cardinality(train_ds).numpy()}\")\n",
    "print(f\"Val batches:   {tf.data.experimental.cardinality(val_ds).numpy()}\")\n",
    "print(f\"Test batches:  {tf.data.experimental.cardinality(test_ds).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee61131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA on train_ds: batch shapes and class distribution\n",
    "\n",
    "\n",
    "# Inspect a single batch\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "\n",
    "# Class distribution in train_ds\n",
    "num_classes = len(class_names)\n",
    "class_counts = np.zeros(num_classes, dtype=int)\n",
    "\n",
    "for _, labels in train_ds:\n",
    "    class_counts += np.bincount(labels.numpy(), minlength=num_classes)\n",
    "\n",
    "for name, count in zip(class_names, class_counts):\n",
    "    print(f\"{name}: {count}\")\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.title(\"Class Distribution in train_ds\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize a few sample images\n",
    "plt.figure(figsize=(10, 6))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize data pipeline\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(\"‚úÖ Data pipeline optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cacfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model_basic = models.Sequential([\n",
    "    # First convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    # layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    # layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_basic.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model_basic.summary()\n",
    "\n",
    "# Train the model\n",
    "history_basic = model_basic.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_basic.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_basic.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_basic.history['loss'], label='Train Loss')\n",
    "plt.plot(history_basic.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model_basic.evaluate(test_ds)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Get one batch from test set\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    predictions = model_basic.predict(images_batch, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Display 12 images\n",
    "    for i in range(min(12, len(images_batch))):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images_batch[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        true_label = class_names[labels_batch[i]]\n",
    "        pred_label = class_names[predicted_classes[i]]\n",
    "        confidence = predictions[i][predicted_classes[i]] * 100\n",
    "        \n",
    "        # Color: green if correct, red if incorrect\n",
    "        color = 'green' if labels_batch[i] == predicted_classes[i] else 'red'\n",
    "        \n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\", \n",
    "                  color=color, fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e07558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model_augmented = models.Sequential([\n",
    "\n",
    "    layers.Rescaling(1./255, input_shape=(64, 64, 3)),\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    # First convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_augmented.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model_augmented.summary()\n",
    "\n",
    "# Train the model\n",
    "history_augmented = model_augmented.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_augmented.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_augmented.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_augmented.history['loss'], label='Train Loss')\n",
    "plt.plot(history_augmented.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model_augmented.evaluate(test_ds)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Get one batch from test set\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    predictions = model_augmented.predict(images_batch, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Display 12 images\n",
    "    for i in range(min(12, len(images_batch))):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images_batch[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        true_label = class_names[labels_batch[i]]\n",
    "        pred_label = class_names[predicted_classes[i]]\n",
    "        confidence = predictions[i][predicted_classes[i]] * 100\n",
    "        \n",
    "        # Color: green if correct, red if incorrect\n",
    "        color = 'green' if labels_batch[i] == predicted_classes[i] else 'red'\n",
    "        \n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\", \n",
    "                  color=color, fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5977e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model_experimental = models.Sequential([\n",
    "\n",
    "    layers.Rescaling(1./255, input_shape=(64, 64, 3)),\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "\n",
    "    # First convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    # layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_experimental.compile(\n",
    "    optimizer='adamw',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model_experimental.summary()\n",
    "\n",
    "# Train the model\n",
    "history_experimental = model_experimental.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=60,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_experimental.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_experimental.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_experimental.history['loss'], label='Train Loss')\n",
    "plt.plot(history_experimental.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model_experimental.evaluate(test_ds)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5391b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Get one batch from test set\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    predictions = model_experimental.predict(images_batch, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Display 12 images\n",
    "    for i in range(min(12, len(images_batch))):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images_batch[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        true_label = class_names[labels_batch[i]]\n",
    "        pred_label = class_names[predicted_classes[i]]\n",
    "        confidence = predictions[i][predicted_classes[i]] * 100\n",
    "        \n",
    "        # Color: green if correct, red if incorrect\n",
    "        color = 'green' if labels_batch[i] == predicted_classes[i] else 'red'\n",
    "        \n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\", \n",
    "                  color=color, fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ca27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compare augmented model to baseline model\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Baseline (model_basic)', 'Augmented (model_augmented)'],\n",
    "    'Train Accuracy': [\n",
    "        history_basic.history['accuracy'][-1],\n",
    "        history_augmented.history['accuracy'][-1]\n",
    "    ],\n",
    "    'Val Accuracy': [\n",
    "        history_basic.history['val_accuracy'][-1],\n",
    "        history_augmented.history['val_accuracy'][-1]\n",
    "    ],\n",
    "    'Train Loss': [\n",
    "        history_basic.history['loss'][-1],\n",
    "        history_augmented.history['loss'][-1]\n",
    "    ],\n",
    "    'Val Loss': [\n",
    "        history_basic.history['val_loss'][-1],\n",
    "        history_augmented.history['val_loss'][-1]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìä Model Comparison Summary:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate both models on test set\n",
    "test_loss_basic, test_acc_basic = model_basic.evaluate(test_ds, verbose=0)\n",
    "test_loss_aug, test_acc_aug = model_augmented.evaluate(test_ds, verbose=0)\n",
    "\n",
    "print(f\"\\nüéØ Test Set Performance:\")\n",
    "print(f\"Baseline Model     - Accuracy: {test_acc_basic:.4f}, Loss: {test_loss_basic:.4f}\")\n",
    "print(f\"Augmented Model    - Accuracy: {test_acc_aug:.4f}, Loss: {test_loss_aug:.4f}\")\n",
    "print(f\"Improvement        - Accuracy: {(test_acc_aug - test_acc_basic):.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training accuracy comparison\n",
    "axes[0, 0].plot(history_basic.history['accuracy'], label='Baseline', linewidth=2)\n",
    "axes[0, 0].plot(history_augmented.history['accuracy'], label='Augmented', linewidth=2)\n",
    "axes[0, 0].set_title('Training Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation accuracy comparison\n",
    "axes[0, 1].plot(history_basic.history['val_accuracy'], label='Baseline', linewidth=2)\n",
    "axes[0, 1].plot(history_augmented.history['val_accuracy'], label='Augmented', linewidth=2)\n",
    "axes[0, 1].set_title('Validation Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss comparison\n",
    "axes[1, 0].plot(history_basic.history['loss'], label='Baseline', linewidth=2)\n",
    "axes[1, 0].plot(history_augmented.history['loss'], label='Augmented', linewidth=2)\n",
    "axes[1, 0].set_title('Training Loss Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation loss comparison\n",
    "axes[1, 1].plot(history_basic.history['val_loss'], label='Baseline', linewidth=2)\n",
    "axes[1, 1].plot(history_augmented.history['val_loss'], label='Augmented', linewidth=2)\n",
    "axes[1, 1].set_title('Validation Loss Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for final metrics\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "metrics = ['Train Acc', 'Val Acc', 'Test Acc']\n",
    "baseline_scores = [\n",
    "    history_basic.history['accuracy'][-1],\n",
    "    history_basic.history['val_accuracy'][-1],\n",
    "    test_acc_basic\n",
    "]\n",
    "augmented_scores = [\n",
    "    history_augmented.history['accuracy'][-1],\n",
    "    history_augmented.history['val_accuracy'][-1],\n",
    "    test_acc_aug\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "ax[0].bar(x - width/2, baseline_scores, width, label='Baseline', alpha=0.8)\n",
    "ax[0].bar(x + width/2, augmented_scores, width, label='Augmented', alpha=0.8)\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('Accuracy Comparison', fontweight='bold')\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].set_xticklabels(metrics)\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "loss_metrics = ['Train Loss', 'Val Loss', 'Test Loss']\n",
    "baseline_losses = [\n",
    "    history_basic.history['loss'][-1],\n",
    "    history_basic.history['val_loss'][-1],\n",
    "    test_loss_basic\n",
    "]\n",
    "augmented_losses = [\n",
    "    history_augmented.history['loss'][-1],\n",
    "    history_augmented.history['val_loss'][-1],\n",
    "    test_loss_aug\n",
    "]\n",
    "\n",
    "ax[1].bar(x - width/2, baseline_losses, width, label='Baseline', alpha=0.8)\n",
    "ax[1].bar(x + width/2, augmented_losses, width, label='Augmented', alpha=0.8)\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_title('Loss Comparison', fontweight='bold')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(loss_metrics)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c76ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Create detailed comparison table with additional metrics\n",
    "\n",
    "\n",
    "# Get predictions for both models on test set\n",
    "test_predictions_basic = []\n",
    "test_labels_list = []\n",
    "test_predictions_aug = []\n",
    "test_predictions_exp = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    pred_basic = model_basic.predict(images, verbose=0)\n",
    "    pred_aug = model_augmented.predict(images, verbose=0)\n",
    "    pred_exp = model_experimental.predict(images, verbose=0)\n",
    "    test_predictions_basic.extend(np.argmax(pred_basic, axis=1))\n",
    "    test_predictions_aug.extend(np.argmax(pred_aug, axis=1))\n",
    "    test_predictions_exp.extend(np.argmax(pred_exp, axis=1))\n",
    "    test_labels_list.extend(labels.numpy())\n",
    "\n",
    "test_predictions_basic = np.array(test_predictions_basic)\n",
    "test_predictions_aug = np.array(test_predictions_aug)\n",
    "test_predictions_exp = np.array(test_predictions_exp)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_basic = f1_score(test_labels_list, test_predictions_basic, average='weighted')\n",
    "f1_aug = f1_score(test_labels_list, test_predictions_aug, average='weighted')\n",
    "f1_exp = f1_score(test_labels_list, test_predictions_exp, average='weighted')\n",
    "\n",
    "# Calculate train-val gaps\n",
    "train_val_gap_basic = history_basic.history['accuracy'][-1] - history_basic.history['val_accuracy'][-1]\n",
    "train_val_gap_aug = history_augmented.history['accuracy'][-1] - history_augmented.history['val_accuracy'][-1]\n",
    "train_val_gap_exp = history_experimental.history['accuracy'][-1] - history_experimental.history['val_accuracy'][-1]\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "comparison_detailed = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Final Train Accuracy',\n",
    "        'Final Val Accuracy',\n",
    "        'Test Accuracy',\n",
    "        'Test F1 Score (Weighted)',\n",
    "        'Train-Val Gap',\n",
    "        'Test Loss'\n",
    "    ],\n",
    "    'Baseline (Basic)': [\n",
    "        f\"{history_basic.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{history_basic.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{test_acc_basic:.4f}\",\n",
    "        f\"{f1_basic:.4f}\",\n",
    "        f\"{train_val_gap_basic:.4f}\",\n",
    "        f\"{test_loss_basic:.4f}\"\n",
    "    ],\n",
    "    'Augmented': [\n",
    "        f\"{history_augmented.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{history_augmented.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{test_acc_aug:.4f}\",\n",
    "        f\"{f1_aug:.4f}\",\n",
    "        f\"{train_val_gap_aug:.4f}\",\n",
    "        f\"{test_loss_aug:.4f}\"\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        f\"{(float(history_augmented.history['accuracy'][-1]) - float(history_basic.history['accuracy'][-1])):.4f}\",\n",
    "        f\"{(float(history_augmented.history['val_accuracy'][-1]) - float(history_basic.history['val_accuracy'][-1])):.4f}\",\n",
    "        f\"{(test_acc_aug - test_acc_basic):.4f}\",\n",
    "        f\"{(f1_aug - f1_basic):.4f}\",\n",
    "        f\"{(train_val_gap_aug - train_val_gap_basic):.4f}\",\n",
    "        f\"{(test_loss_aug - test_loss_basic):.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìã COMPREHENSIVE MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_detailed.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "\n",
    "# Detailed classification report for basic model\n",
    "print(\"\\nüìä Classification Report - Basic Model (Test Set):\")\n",
    "print(classification_report(test_labels_list, test_predictions_basic, target_names=class_names))\n",
    "\n",
    "\n",
    "# Detailed classification report for augmented model\n",
    "print(\"\\nüìä Classification Report - Augmented Model (Test Set):\")\n",
    "print(classification_report(test_labels_list, test_predictions_aug, target_names=class_names))\n",
    "\n",
    "\n",
    "# Detailed classification report for experimental model\n",
    "print(\"\\nüìä Classification Report - Experimental Model (Test Set):\")\n",
    "print(classification_report(test_labels_list, test_predictions_exp, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare augmented model to experimental model\n",
    "\n",
    "# Evaluate experimental model on test set\n",
    "test_loss_exp, test_acc_exp = model_experimental.evaluate(test_ds, verbose=0)\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_exp = f1_score(test_labels_list, test_predictions_exp, average='weighted')\n",
    "\n",
    "# Calculate train-val gaps\n",
    "train_val_gap_exp = history_experimental.history['accuracy'][-1] - history_experimental.history['val_accuracy'][-1]\n",
    "\n",
    "# Create comprehensive comparison table (Augmented vs Experimental)\n",
    "comparison_aug_exp = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Final Train Accuracy',\n",
    "        'Final Val Accuracy',\n",
    "        'Test Accuracy',\n",
    "        'Train-Val Gap',\n",
    "        'Test Loss'\n",
    "    ],\n",
    "    'Augmented': [\n",
    "        f\"{history_augmented.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{history_augmented.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{test_acc_aug:.4f}\",\n",
    "        f\"{train_val_gap_aug:.4f}\",\n",
    "        f\"{test_loss_aug:.4f}\"\n",
    "    ],\n",
    "    'Experimental': [\n",
    "        f\"{history_experimental.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{history_experimental.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{test_acc_exp:.4f}\",\n",
    "        f\"{train_val_gap_exp:.4f}\",\n",
    "        f\"{test_loss_exp:.4f}\"\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        f\"{(float(history_experimental.history['accuracy'][-1]) - float(history_augmented.history['accuracy'][-1])):.4f}\",\n",
    "        f\"{(float(history_experimental.history['val_accuracy'][-1]) - float(history_augmented.history['val_accuracy'][-1])):.4f}\",\n",
    "        f\"{(test_acc_exp - test_acc_aug):.4f}\",\n",
    "        f\"{(train_val_gap_exp - train_val_gap_aug):.4f}\",\n",
    "        f\"{(test_loss_exp - test_loss_aug):.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìä AUGMENTED vs EXPERIMENTAL MODEL COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_aug_exp.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Plot comparison: Augmented vs Experimental\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training accuracy comparison\n",
    "axes[0, 0].plot(history_augmented.history['accuracy'], label='Augmented', linewidth=2)\n",
    "axes[0, 0].plot(history_experimental.history['accuracy'], label='Experimental', linewidth=2)\n",
    "axes[0, 0].set_title('Training Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation accuracy comparison\n",
    "axes[0, 1].plot(history_augmented.history['val_accuracy'], label='Augmented', linewidth=2)\n",
    "axes[0, 1].plot(history_experimental.history['val_accuracy'], label='Experimental', linewidth=2)\n",
    "axes[0, 1].set_title('Validation Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss comparison\n",
    "axes[1, 0].plot(history_augmented.history['loss'], label='Augmented', linewidth=2)\n",
    "axes[1, 0].plot(history_experimental.history['loss'], label='Experimental', linewidth=2)\n",
    "axes[1, 0].set_title('Training Loss Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation loss comparison\n",
    "axes[1, 1].plot(history_augmented.history['val_loss'], label='Augmented', linewidth=2)\n",
    "axes[1, 1].plot(history_experimental.history['val_loss'], label='Experimental', linewidth=2)\n",
    "axes[1, 1].set_title('Validation Loss Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for final metrics\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "metrics = ['Train Acc', 'Val Acc', 'Test Acc']\n",
    "augmented_scores = [\n",
    "    history_augmented.history['accuracy'][-1],\n",
    "    history_augmented.history['val_accuracy'][-1],\n",
    "    test_acc_aug\n",
    "]\n",
    "experimental_scores = [\n",
    "    history_experimental.history['accuracy'][-1],\n",
    "    history_experimental.history['val_accuracy'][-1],\n",
    "    test_acc_exp\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "ax[0].bar(x - width/2, augmented_scores, width, label='Augmented', alpha=0.8)\n",
    "ax[0].bar(x + width/2, experimental_scores, width, label='Experimental', alpha=0.8)\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('Accuracy Comparison', fontweight='bold')\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].set_xticklabels(metrics)\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "loss_metrics = ['Train Loss', 'Val Loss', 'Test Loss']\n",
    "augmented_losses = [\n",
    "    history_augmented.history['loss'][-1],\n",
    "    history_augmented.history['val_loss'][-1],\n",
    "    test_loss_aug\n",
    "]\n",
    "experimental_losses = [\n",
    "    history_experimental.history['loss'][-1],\n",
    "    history_experimental.history['val_loss'][-1],\n",
    "    test_loss_exp\n",
    "]\n",
    "\n",
    "ax[1].bar(x - width/2, augmented_losses, width, label='Augmented', alpha=0.8)\n",
    "ax[1].bar(x + width/2, experimental_losses, width, label='Experimental', alpha=0.8)\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_title('Loss Comparison', fontweight='bold')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(loss_metrics)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.Input(shape=(64, 64, 3))\n",
    "\n",
    "for model_name, model in [(\"Basic\", model_basic), (\"Augmented\", model_augmented), (\"Experimental\", model_experimental)]:\n",
    "    x = inp\n",
    "    conv_outputs = []\n",
    "    conv_names = []\n",
    "    for layer in model.layers:\n",
    "        x = layer(x)\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            conv_outputs.append(x)\n",
    "            conv_names.append(layer.name)\n",
    "            print(f\"  {layer.name}: output shape = {x.shape}\")\n",
    "\n",
    "    feature_map_model = models.Model(inputs=inp, outputs=conv_outputs)\n",
    "\n",
    "    print(f\"Class mapping: {class_names}\")\n",
    "\n",
    "    green_area_class = class_names.index('green_area') if 'green_area' in class_names else 0\n",
    "    water_class = class_names.index('water') if 'water' in class_names else 0\n",
    "\n",
    "    for images, labels_batch in val_ds.take(1):\n",
    "        green_area_idx = None\n",
    "        water_idx = None\n",
    "        for i in range(len(labels_batch)):\n",
    "            label = int(labels_batch[i].numpy())\n",
    "            if label == green_area_class and green_area_idx is None:\n",
    "                green_area_idx = i\n",
    "            elif label == water_class and water_idx is None:\n",
    "                water_idx = i\n",
    "            if green_area_idx is not None and water_idx is not None:\n",
    "                break\n",
    "\n",
    "        test_green_area = images[green_area_idx]\n",
    "        test_water = images[water_idx]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax1.imshow(test_green_area.numpy().astype('uint8'))\n",
    "    ax1.set_title('Test: Green Area', fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(test_water.numpy().astype('uint8'))\n",
    "    ax2.set_title('Test: Water', fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    plt.suptitle(f\"{model_name} Model - Test Image Selection\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    test_input = tf.expand_dims(test_green_area, 0)\n",
    "    feature_maps = feature_map_model.predict(test_input, verbose=0)\n",
    "\n",
    "    # conv_names was defined in the cell above\n",
    "\n",
    "    for layer_idx, feature_map in enumerate(feature_maps):\n",
    "        num_filters = feature_map.shape[-1]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        for i in range(min(16, num_filters)):\n",
    "            plt.subplot(2, 8, i + 1)\n",
    "            plt.imshow(feature_map[0, :, :, i], cmap='viridis')\n",
    "            plt.title(f'{conv_names[layer_idx]} - Filter {i}', fontsize=9)\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Feature Maps from Layer: {conv_names[layer_idx]}', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35749c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, model in [(\"Basic\", model_basic), (\"Augmented\", model_augmented), (\"Experimental\", model_experimental)]:\n",
    "    print(f\"\\nüîç Visualizing Learned Filters for {model_name} Model:\")\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            filters, biases = layer.get_weights()\n",
    "            print(f\"\\nLayer: {layer.name}, Filter shape: {filters.shape}\")\n",
    "\n",
    "        num_filters = filters.shape[-1]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        for i in range(min(16, num_filters)):\n",
    "            f = filters[:, :, :, i]\n",
    "            if f.shape[2] == 3:\n",
    "                # First layer: display as RGB\n",
    "                f_min, f_max = f.min(), f.max()\n",
    "                f_norm = (f - f_min) / (f_max - f_min + 1e-5)\n",
    "                plt.subplot(2, 8, i + 1)\n",
    "                plt.imshow(f_norm)\n",
    "                plt.title(f'{layer.name} - Filter {i}', fontsize=9)\n",
    "                plt.axis('off')\n",
    "            else:\n",
    "                # Deeper layers: show mean across input channels\n",
    "                f_mean = np.mean(f, axis=-1)\n",
    "                f_min, f_max = f_mean.min(), f_mean.max()\n",
    "                f_norm = (f_mean - f_min) / (f_max - f_min + 1e-5)\n",
    "                plt.subplot(2, 8, i + 1)\n",
    "                plt.imshow(f_norm, cmap='viridis')\n",
    "                plt.title(f'{layer.name} - Filter {i}', fontsize=9)\n",
    "                plt.axis('off')\n",
    "        plt.suptitle(f'Learned Filters from Layer: {layer.name}', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
